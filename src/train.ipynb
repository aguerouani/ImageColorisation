{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1494ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from torch import nn\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c26efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_to_rgb(L, ab):\n",
    "    \"\"\"\n",
    "    L is (1,H,W), ab is (2,H,W), both torch tensors.\n",
    "    L is in [0,1], ab is in [-1,1].\n",
    "    We convert them back to LAB then RGB.\n",
    "    \"\"\"\n",
    "    L = L[0].cpu().numpy()          # (H,W)\n",
    "    ab = ab.cpu().numpy().transpose(1,2,0)  # (H,W,2)\n",
    "\n",
    "    # Undo normalization\n",
    "    L = L * 100\n",
    "    ab = ab * 128\n",
    "\n",
    "    lab = np.concatenate([L[..., np.newaxis], ab], axis=2)  # (H,W,3)\n",
    "    rgb = lab2rgb(lab)  # returns floats in [0,1]\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b31aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGB2LabDataset(Dataset):\n",
    "    def __init__(self, image_dir, image_size=256, extensions=('.jpg','.jpeg','.png','.bmp','.webp')):\n",
    "        self.image_paths = [\n",
    "            os.path.join(image_dir, f)\n",
    "            for f in os.listdir(image_dir)\n",
    "            if f.lower().endswith(extensions)\n",
    "        ]\n",
    "        if len(self.image_paths) == 0:\n",
    "            raise RuntimeError(f\"No images found in {image_dir}\")\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize((image_size, image_size)),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self): return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        x = self.transform(img)\n",
    "        x_np = x.permute(1,2,0).numpy().astype(np.float32)\n",
    "        lab = rgb2lab(x_np).astype(\"float32\")\n",
    "\n",
    "        L  = lab[...,0] / 100.0\n",
    "        ab = lab[...,1:] / 128.0\n",
    "\n",
    "        L  = torch.from_numpy(L).unsqueeze(0)\n",
    "        ab = torch.from_numpy(ab).permute(2,0,1)\n",
    "        return L, ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f139b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 3, 3),    # (254, 254, 3)\n",
    "            nn.MaxPool2d(2),       # (127, 127, 3)\n",
    "            nn.Conv2d(3, 9, 3),    # (125, 125, 9)\n",
    "            nn.MaxPool2d(2),       # (62, 62, 9)\n",
    "            nn.Conv2d(9, 27, 3),   # (60, 60, 27)\n",
    "            nn.MaxPool2d(2),       # (30, 30, 27)\n",
    "            nn.Conv2d(27, 81, 3),  # (28, 28, 81)\n",
    "            nn.MaxPool2d(2),       # (14, 14, 81)\n",
    "            nn.Conv2d(81, 243, 3), # (12, 12, 243)\n",
    "            nn.MaxPool2d(2),       # (6, 6, 243) # Corrected output size after pooling\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(243, 243, kernel_size=2, stride=2, padding=0, output_padding=0),  # 6 -> 12\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(243, 81,  kernel_size=3, stride=1, padding=0),                    # 12 -> 14\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 14 -> 28 -> 30\n",
    "            nn.ConvTranspose2d(81,  81,  kernel_size=2, stride=2, padding=0, output_padding=0),  # 14 -> 28\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(81,  27,  kernel_size=3, stride=1, padding=0),                    # 28 -> 30\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 30 -> 60 -> 62\n",
    "            nn.ConvTranspose2d(27,  27,  kernel_size=2, stride=2, padding=0, output_padding=0),  # 30 -> 60\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(27,  9,   kernel_size=3, stride=1, padding=0),                    # 60 -> 62\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 62 -> 125 -> 127 \n",
    "            nn.ConvTranspose2d(9,   9,   kernel_size=2, stride=2, padding=0, output_padding=1),  # 62 -> 125\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(9,   3,   kernel_size=3, stride=1, padding=0),                    # 125 -> 127\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 127 -> 254 -> 256\n",
    "            nn.ConvTranspose2d(3,   3,   kernel_size=2, stride=2, padding=0, output_padding=0),  # 127 -> 254\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(3,   1, kernel_size=3, stride=1, padding=0),\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1309f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for L, ab in loader:\n",
    "        L = L.to(device)\n",
    "        ab = ab.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(L)\n",
    "        loss = criterion(outputs, L)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for L, ab in loader:\n",
    "            L = L.to(device)\n",
    "            ab = ab.to(device)\n",
    "            outputs = model(L)\n",
    "            loss = criterion(outputs, L)\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9f98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739cb368",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RGB2LabDataset(\"../Data/DIV2K_train_LR_bicubic/X2/\", image_size=256)\n",
    "\n",
    "# Split dataset into training and evaluation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "eval_size = len(dataset) - train_size\n",
    "train_dataset, eval_dataset = random_split(dataset, [train_size, eval_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1533c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AE().to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "model = AE().to(device)\n",
    "summary(model, input_size=(1, 256, 256), device=str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a2d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    eval_loss = evaluate(model, eval_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Eval Loss: {eval_loss:.4f}\")\n",
    "    \n",
    "model.eval()\n",
    "L_batch, ab_batch = next(iter(eval_loader))\n",
    "L_batch, ab_batch = L_batch.to(device), ab_batch.to(device)\n",
    "with torch.no_grad():\n",
    "    pred_L_batch = model(L_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c4783",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_show = 5\n",
    "plt.figure(figsize=(12, num_show * 3))\n",
    "\n",
    "for i in range(num_show):\n",
    "    L = L_batch[i]\n",
    "    ab_gt = ab_batch[i]\n",
    "    L_pred = pred_L_batch[i]\n",
    "\n",
    "    # Convert to RGB\n",
    "    rgb_gt = lab_to_rgb(L, ab_gt)\n",
    "    rgb_pred = lab_to_rgb(L_pred, ab_gt)\n",
    "\n",
    "    # Input grayscale for visualization\n",
    "    grayscale = L[0].cpu().numpy()\n",
    "\n",
    "    # Plot\n",
    "    plt.subplot(num_show, 3, i*3 + 1)\n",
    "    plt.imshow(grayscale, cmap='gray')\n",
    "    plt.title(\"Input L\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(num_show, 3, i*3 + 2)\n",
    "    plt.imshow(rgb_gt)\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(num_show, 3, i*3 + 3)\n",
    "    plt.imshow(rgb_pred)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
